{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de NLP_Tuto.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WEHqOHRrsEk",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Toolkit (NLTK)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLI7a97Yr8wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZtGJ5NmvVP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WgRV9YFsL9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = nltk.word_tokenize(sentence)\n",
        "tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGm9lA0SsQMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBxnBFzPt-PO",
        "colab_type": "text"
      },
      "source": [
        "**Extensive list Part Of Speech (POS) tag**\n",
        " *   CC coordinating conjunction\n",
        " *   CD cardinal digit\n",
        " *   DT determiner\n",
        " *   EX existential there (like: \"there is\" ... think of it like \"there exists\")\n",
        " *   FW foreign word\n",
        " *   IN preposition/subordinating conjunction\n",
        " *   JJ adjective 'big'\n",
        " *   JJR adjective, comparative 'bigger'\n",
        " *   JJS adjective, superlative 'biggest'\n",
        " *   LS list marker 1)\n",
        " *   MD modal could, will\n",
        " *   NN noun, singular 'desk'\n",
        " *   NNS noun plural 'desks'\n",
        " *   NNP proper noun, singular 'Harrison'\n",
        " *   NNPS proper noun, plural 'Americans'\n",
        " *   PDT predeterminer 'all the kids'\n",
        " *   POS possessive ending parent's\n",
        " *   PRP personal pronoun I, he, she\n",
        " *   PRP\\$ possessive pronoun my, his, hers\n",
        " *   RB adverb very, silently,\n",
        " *   RBR adverb, comparative better\n",
        " *   RBS adverb, superlative best\n",
        " *   RP particle give up\n",
        " *   TO to go 'to' the store.\n",
        " *   UH interjection errrrrrrrm\n",
        " *   VB verb, base form take\n",
        " *   VBD verb, past tense took\n",
        " *   VBG verb, gerund/present participle taking\n",
        " *   VBN verb, past participle taken\n",
        " *   VBP verb, sing. present, non-3d take\n",
        " *   VBZ verb, 3rd person sing. present takes\n",
        " *   WDT wh-determiner which\n",
        " *   WP wh-pronoun who, what\n",
        " *   WP\\$ possessive wh-pronoun whose\n",
        " *   WRB wh-abverb where, when\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al4GsbT3v5eN",
        "colab_type": "code",
        "outputId": "b433f2cf-fad6-47c4-827e-262e95cbdaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from nltk.sentiment.util import mark_negation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U9T3nzYwYYp",
        "colab_type": "code",
        "outputId": "047bd5a9-9d87-4b09-da6d-2478fa2f5d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sent = \"I didn't like this movie . It was bad .\".split()\n",
        "mark_negation(sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " \"didn't\",\n",
              " 'like_NEG',\n",
              " 'this_NEG',\n",
              " 'movie_NEG',\n",
              " '.',\n",
              " 'It',\n",
              " 'was',\n",
              " 'bad',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJeRKWerxL0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL_aCIet0IbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence1 = \"I hate running\"\n",
        "sentence2 = \"I love NLP\"\n",
        "list_sentence = [sentence1, sentence2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trth1hPVxyTV",
        "colab_type": "code",
        "outputId": "2b7cdb0f-40e4-4e5c-88a1-8bfd7c9f09a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "for sentence in list_sentence:\n",
        "  print(sentence, SentimentIntensityAnalyzer().polarity_scores(sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I hate running {'neg': 0.787, 'neu': 0.213, 'pos': 0.0, 'compound': -0.5719}\n",
            "I love NLP {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMiP3h8H1vWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_XfwESS1wib",
        "colab_type": "text"
      },
      "source": [
        "# TEXT Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdTnjY8o131e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "def clean_data(lines):\n",
        "  # prepare translation table for removing punctuation\n",
        "  clean_text = list()\n",
        "  for line in lines:\n",
        "    # tokenize on white space\n",
        "    line = re.sub('[éëèêë]', 'e', line)\n",
        "    line =re.sub('[áàâä]','a', line)\n",
        "    line =re.sub('[ù]','u', line)\n",
        "    line = line.split()\n",
        "    # convert to lowercase\n",
        "    line = [word.lower() for word in line]\n",
        "    line = [w.strip() for w in line]\n",
        "    # store as string\n",
        "    clean_text.append(' '.join(line))\n",
        "  return np.array(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJjKKqui1_zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = ['ésmi   Ahmed w oùmri 10 snin', 'le NLP est interessant', 'le nlp ést interessant']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StIQRbAl2g92",
        "colab_type": "code",
        "outputId": "332487ca-6d3f-45c6-fe4a-96a652518a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "clean_data(sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['esmi ahmed w oumri 10 snin', 'le nlp est interessant',\n",
              "       'le nlp est interessant'], dtype='<U26')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60nA88wW28D2",
        "colab_type": "code",
        "outputId": "05e9abb3-b005-4729-b77c-f5e5a3336283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = list(set(stopwords.words('english')))\n",
        "sentence = \"a set of words that is complete in itself, typically containing a subject and predicate, conveying a statement, question, \\\n",
        "              exclamation, or command, and consisting of a main clause and sometimes one or more subordinate clauses.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "preserved = [w for w in tokens if not w in stop_words]\n",
        "preserved"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['set',\n",
              " 'words',\n",
              " 'complete',\n",
              " ',',\n",
              " 'typically',\n",
              " 'containing',\n",
              " 'subject',\n",
              " 'predicate',\n",
              " ',',\n",
              " 'conveying',\n",
              " 'statement',\n",
              " ',',\n",
              " 'question',\n",
              " ',',\n",
              " 'exclamation',\n",
              " ',',\n",
              " 'command',\n",
              " ',',\n",
              " 'consisting',\n",
              " 'main',\n",
              " 'clause',\n",
              " 'sometimes',\n",
              " 'one',\n",
              " 'subordinate',\n",
              " 'clauses',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReUROyBC3R-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyrAiwlA3lpH",
        "colab_type": "text"
      },
      "source": [
        "# Web Scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTAyiowL3vXJ",
        "colab_type": "code",
        "outputId": "84c8aae9-8b91-40ae-b03f-effb27c132e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from urllib.request import urlopen\n",
        "!pip install bs4\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNxGsp3G378v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = urlopen(\"http://www.asslemafm.net/2019/01/bejikaidsebsijournal04012019.html?fbclid=IwAR2QhzxeXorQ1w9IybSAvkVVj3UP95LVgNOLKd8BfM3wz8R7Mu5jXY3S4aA\")\n",
        "bs = BeautifulSoup(url, \"html.parser\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZww-iRq3__W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag =bs.find('div',itemprop=\"articleBody\")\n",
        "l = tag.find_all('b')\n",
        "res = ''\n",
        "for x in l :\n",
        "  res += ' '+ x.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjWabdQ44GPn",
        "colab_type": "code",
        "outputId": "5d376597-590c-4d88-be6e-eedd16351e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' خلال إستقباله أمس، الخميس 3 جانفي 2019، لأعضاء الهيئة المديرة للجامعة التونسيّة لمديري الصحف، شدد رئيس الجمهورية الباجي قائد السبسي على الدور الأساسي للصحافة في تدعيم وحماية المسار الديمقراطي في تونس وعبّر عن تفهّمه لمشاغل القطاع وأكد حرصه الشخصي على ضمان المناخ الملائم والإمكانيّات الضرورية لتطوير قطاع الصحافة الورقيّة والإكترونية، وتقديم ما يلزم من دعم ومساندة بالتنسيق مع الحكومة ومجلس نواب الشعب خاصة من خلال العمل على التسريع بمناقشة مشروع قانون إحداث الوكالة الوطنية للتصرّف في الإشهار العمومي والإشتراكات. وفي معرض حديثه عن الأزمة التي تمر بها الصحف التونسي، أشار إلى أنه على وعي تام بهذه الأزمة وبعمقها، وقال “لست مستعدا أن أنهض الخامسة صباحا ولا أجد صحفا أقرأها ” . وكان اللقاء قد إستعرض مشاغل قطاع الصحافة الورقيّة والاكترونيّة والمشاكل التي يمرّ بها القطاع وخاصة الصعوبات الماديّة للمؤسّسات الاعلاميّة وضرورة توفير مداخيل قارة لها عبر التوزيع العادل للاشتراكات والإشهار العمومي وفق مقاييس موضوعيّة وشفّافة لا حسب الولاءات. وأكد رئيس الجمهورية أنه متابع للصحف التونسية وإستحضر أمام أعضاء الهيئة المديرة لجمعية مديري الصحف فحوى عدة مقالات ونصوص منها القديمة والجديدة .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x475bOdzi5t1",
        "colab_type": "code",
        "outputId": "e13439ea-3928-4404-8b27-e1a26b308918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.cast(s[:, :, np.newaxis, np.newaxis], x.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7699618d25c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwy7xkINeGFk",
        "colab_type": "code",
        "outputId": "155590e5-9f8e-4e2a-dcda-514e51c3688f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import numpy as np\n",
        "p1 = np.array([[[1, 2] , [1, 2]], [[1, 2] , [1, 2]]] * 2 )\n",
        "p2 = np.array([[[5, 3], [5, 3]], [[5, 3], [5, 3]]] * 2 )\n",
        "p1 + [] + p2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-94424d007dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,2,2) (0,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNlcP3XFJ3FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}